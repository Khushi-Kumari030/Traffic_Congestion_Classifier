# -*- coding: utf-8 -*-
"""Traffic_Congestion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y9Me60sbIal1jWLpSP7DsI0Tev7foMbi
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split

df=pd.read_csv('/content/Banglore_traffic.csv')
df.head(1)

df.info()

df.describe()

df['Area Name'].value_counts()

df_numeric = df.select_dtypes(include='number')
correlation_matrix = df_numeric.corrwith(df['Congestion Level'])
print(correlation_matrix)

#taking top 6 features based on Correlation matrix
df_new=df.drop(['Date','Road/Intersection Name','Road Capacity Utilization','Incident Reports','Weather Conditions','Roadwork and Construction Activity','Parking Usage','Traffic Signal Compliance','Public Transport Usage'],axis=1)

df_new.head(1)

sns.heatmap(df_new.select_dtypes(include='number').corr(),annot=True)

# Define bins and labels
bins = [0, 60, 90, 100]
labels = ['low', 'medium', 'high']

# Create new categorical column
df_new['Congestion Category'] = pd.cut(df_new['Congestion Level'], bins=bins, labels=labels, include_lowest=True)

# Optional: Check value counts
print(df_new['Congestion Category'].value_counts())

df_new.drop('Congestion Level',axis=1,inplace=True)

label_order = {'low': 0, 'medium': 1, 'high': 2}

# Apply mapping
df_new['Congestion Category Encoded'] = df_new['Congestion Category'].map(label_order)

# Check result
print(df_new[['Congestion Category', 'Congestion Category Encoded']].head())

df_new.drop('Congestion Category',axis=1,inplace=True)

df_new.head(1)

sns.scatterplot(x='Average Speed',y='Traffic Volume',hue='Congestion Category Encoded',data=df_new)

sns.displot(data=df_new,x='Average Speed',hue='Congestion Category Encoded',kind='kde')

sns.barplot(x='Congestion Category Encoded',y='Traffic Volume',data=df_new)

sns.barplot(x='Congestion Category Encoded',y='Average Speed',data=df_new)

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

X = df_new.drop(columns=['Congestion Category Encoded'])  # adjust as needed
y = df_new['Congestion Category Encoded']


numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

#Preprocessing for numerical features
numerical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', MinMaxScaler())
])

#Preprocessing for categorical features
categorical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

#Combine preprocessing
preprocessor = ColumnTransformer(transformers=[
    ('num', numerical_pipeline, numerical_cols),
    ('cat', categorical_pipeline, categorical_cols)
])

#Final pipeline with Random Forest
final_pipeline = Pipeline(steps=[
    ('preprocessing', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

#Fit the pipeline
final_pipeline.fit(X_train, y_train)

y_pred = final_pipeline.predict(X_test)

print("Classification Report:\n", classification_report(y_test, y_pred))

import pickle
with open('rf_pipeline_new_model.pkl', 'wb') as file:
    pickle.dump(final_pipeline, file)

print("Model saved as 'rf_pipeline_new_model.pkl'")

import json

# Save feature names
with open("new_feature_columns.json", "w") as f:
    json.dump(X.columns.tolist(), f)